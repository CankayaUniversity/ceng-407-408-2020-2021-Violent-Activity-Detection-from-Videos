{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "opticalflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpDG0NLsT2WK"
      },
      "source": [
        "#Mount Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OzL6N9tT5DP"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import glob\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
        "from numpy import savetxt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flV-fSAgTuYr"
      },
      "source": [
        "\n",
        "videoid2 = 1\n",
        "videoid = 0\n",
        "sample = 0\n",
        "sample2 = 0\n",
        "magnitudeList = list()\n",
        "orientationList = list()\n",
        "magorientList = []\n",
        "magorientVector = []\n",
        "magorient3DVector = []\n",
        "labelArray = []\n",
        "path = ('/path/*.*')  #Give a path for specific folder to read videos\n",
        "video_list = []\n",
        "VideoCounter = 0   #Video counter value holds number of videos\n",
        "\n",
        "\n",
        "def videopath():  #In this  code segment videos is sending one by one to opticalflow function\n",
        "    global VideoCounter\n",
        "    i = 0\n",
        "    for video in glob.glob(path):\n",
        "        a = cv.imread(video)\n",
        "        video_list.insert(VideoCounter, video)\n",
        "        VideoCounter = VideoCounter + 1\n",
        "    while i != VideoCounter:\n",
        "        opticalflow(video_list[i])\n",
        "        i = i + 1\n",
        "\n",
        "textfile = open(\"Magnitude.txt\", \"w\")\n",
        "textfile1 = open(\"Orientation.txt\", \"w\")\n",
        "textfile2 = open(\"Megorientation.txt\", \"w\")\n",
        "\n",
        "\n",
        "def opticalflow(video):\n",
        "    global videoid\n",
        "    print(video)\n",
        "    capture = cv.VideoCapture(video)  #Capture the video\n",
        "    ret, frame = capture.read()       #Getting frames from the video\n",
        "    prvs = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)    \n",
        "    hsv = np.zeros_like(frame)\n",
        "    hsv[..., 1] = 244\n",
        "    frameCounter = 0   #frame counter holds the value that frame we have\n",
        "    counter = 0\n",
        "    videoid = videoid + 1\n",
        "    try:  \n",
        "        while(1):\n",
        "            ret = capture.grab()  # grabing the frame\n",
        "            frameCounter = frameCounter + 1  # increment counter\n",
        "            if frameCounter % 5 == 2:  # # display and detect only fifth of the frames,\n",
        "                counter = counter + 1\n",
        "                ret, frame = capture.retrieve()  # decoding the frame\n",
        "                if ret:\n",
        "                    ret2, frame2 = capture.read()\n",
        "                    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
        "                    flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "                    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])  # Extracting the attributes magnitude and angle (orientation)\n",
        "                    hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "                    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n",
        "                    rgb = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
        "                    systemVertical = np.concatenate((frame2, rgb), axis=1)\n",
        "                    #cv.imshow('opticalflow', systemVertical)                                 \n",
        "                    magnitudeList = np.asarray(mag)\n",
        "                    orientationList = np.asarray(ang)\n",
        "                    magorientList = mag *ang   # magOrientedList holds the value that multiplication of attributes(mag and orientation)\n",
        "                    magorientList = np.resize(magorientList, (224, 224, 3) )  #Resize the magnitude and angle to function vGG16\n",
        "                    print('MAGORIENTED: ', magorientList)\n",
        "                    transformedImage = np.expand_dims(magorientList, axis = 0)               \n",
        "                    textfile.write(str(mag))                   \n",
        "                    textfile1.write(str(ang))                    #Creating the text file for each attribute and their multiplication\n",
        "                    textfile2.write(str(mag*ang))                  \n",
        "                    print(counter)\n",
        "                    vGG16(magorientList, videoid)    #Function call for vGG16\n",
        "                    prvs = next\n",
        "                    if cv.waitKey(1) & 0xFF == ord('q'):\n",
        "                        break\n",
        "                else:\n",
        "                    return\n",
        "\n",
        "    except:\n",
        "        capture.release()\n",
        "        cv.destroyAllWindows()\n",
        "\n",
        "def vGG16(magorientList, videoid):\n",
        "    global magorientVector\n",
        "    global videoid2\n",
        "    global sample\n",
        "    global sample2\n",
        "    sample = sample + 1\n",
        "    if(videoid == videoid2):     \n",
        "        model = VGG16(weights='imagenet', include_top=True)                  #model call vGG16 for transferLearning\n",
        "        transformedImage = np.expand_dims(magorientList, axis = 0)      #To add additional dimension for keras application\n",
        "        print(transformedImage.shape)\n",
        "        transformedImage = preprocess_input(transformedImage)    #preprocess_input function properly transforms a standard matrice into the format which model requires.\n",
        "        print(transformedImage)       #print matrices\n",
        "        prediction = model.predict(transformedImage)      #predict() function classify input matrices in 1000 possible classes.\n",
        "        print('prediction shape', prediction.shape)\n",
        "        print('prediction', prediction)\n",
        "        magorientVector.append(prediction)       #Append the vector list to magorientVector\n",
        "        if(sample % 30 == 0):                  \n",
        "            sample2 = sample2 + 1\n",
        "            np_magorientVector = np.array(magorientVector)   #magorientVector is a 3dvector holds that every 30 samples of the fifth frames\n",
        "            magorient3DVector.append(np_magorientVector)\n",
        "            magorientVector.clear()\n",
        "            transformedImage2 = np.expand_dims(magorient3DVector, axis = 0)\n",
        "            print(transformedImage2.shape)\n",
        "    else:\n",
        "      sample = 0\n",
        "      videoid2 = videoid\n",
        "      magorientVector.clear()\n",
        "\n",
        "videopath()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cU_51_5UFke"
      },
      "source": [
        "np_magorient3DVector = np.asarray(magorient3DVector)\n",
        "np_magorient3DVector.shape\n",
        "np_magorient3DVector = np.squeeze(np_magorient3DVector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DntEjV3qUU3X"
      },
      "source": [
        "import numpy\n",
        "import numpy as gfg\n",
        "\n",
        "np_magorient3DVector_reshaped = np_magorient3DVector.reshape(np_magorient3DVector.shape[0], -1)\n",
        "gfg.savetxt(\"Dataset.txt\", np_magorient3DVector_reshaped)\n",
        "loaded_newArray = gfg.loadtxt(\"Dataset.txt\")\n",
        "\n",
        "load_original_newArray = loaded_newArray.reshape(loaded_newArray.shape[0], loaded_newArray.shape[1] // np_magorient3DVector.shape[2], np_magorient3DVector.shape[2])\n",
        "\n",
        "print(\"shape of arr: \", np_magorient3DVector.shape)\n",
        "print(\"shape of load_original_arr: \", load_original_newArray.shape)\n",
        "\n",
        "if (load_original_newArray == np_newArray).all():\n",
        "    print(\"Yes, both the arrays are same\")\n",
        "else:\n",
        "    print(\"No, both the arrays are not same\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA7uEUn7U2d4"
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "#fight1= open(, \"r\")\n",
        "# Read the array from disk\n",
        "text_fight_data = np.loadtxt(\"/path/\")\n",
        "\n",
        "# Note that this returned a 2D array!\n",
        "print (text_fight_data.shape)\n",
        "\n",
        "# However, going back to 3D is easy if we know the \n",
        "# original shape of the array\n",
        "fight_3D_data = text_fight_data.reshape((1548,30,1000))\n",
        "    \n",
        "# Just to check that they're the same...\n",
        "print(fight_3D_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRz8ti9fVS6J"
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "#fight1= open(, \"r\")\n",
        "# Read the array from disk\n",
        "text_normal_data = np.loadtxt(\"/path/\")\n",
        "\n",
        "# Note that this returned a 2D array!\n",
        "print (text_normal_data.shape)\n",
        "\n",
        "# However, going back to 3D is easy if we know the \n",
        "# original shape of the array\n",
        "normal6_3D_data = text_normal_data.reshape((784,30,1000))\n",
        "print (normal_3D_data.shape)\n",
        "    \n",
        "# Just to check that they're the same...\n",
        "print(normal_3D_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64FSrKO6U4f_"
      },
      "source": [
        "data = np.vstack((fight_3D_data, normal_3D_data))\n",
        "\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCrnOWFRWh0w"
      },
      "source": [
        "import numpy\n",
        "import numpy as gfg\n",
        "\n",
        "data_reshaped = data.reshape(data.shape[0], -1)\n",
        "gfg.savetxt(\"Dataset.txt\", data_reshaped)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}